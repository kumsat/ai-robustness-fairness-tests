# ğŸ§ª AI Robustness & Fairness Test Suite

### Automated Testing Framework for Evaluating AI Text Classification Reliability

This project demonstrates how to design **automated robustness and fairness tests** for an AI text classification system.  
It includes a **local mock AI model**, **pytest test suite**, and **professional QA engineering structure** suitable for real-world AI/ML testing.

The goal is to validate that an AI classifier is:

- **Robust** â†’ consistent predictions despite formatting noise  
- **Fair** â†’ consistent predictions across demographic variations  
- **Reliable** â†’ correctly handles malformed or missing inputs  

---

## â­ Key Features

- **Robustness Testing**  
  Ensures consistent predictions across:
  - Upper/lower case  
  - Extra spaces  
  - Punctuation  
  - Text permutations  

- âš–ï¸ **Fairness Testing**  
  Ensures same sentiment/label for:
  - Male vs Female terms  
  - Nationality swaps  
  - Similar structured sentences  

- **Negative Testing**
  - Missing payload  
  - Empty text  
  - Invalid types  

- **Local Flask-Based Mock AI Service**  
  Fully controlled & predictable behavior for safe testing.

- **Clean Pytest Setup**  
  Reusable, parametrized tests, modular utilities.

---

## ğŸ“ Project Structure

```text
ai-robustness-fairness-tests/
â”œâ”€â”€ mock_api/              # Local AI model simulation (Flask)
â”‚   â””â”€â”€ server.py
â”œâ”€â”€ utils/                 # API client and helper utilities
â”‚   â””â”€â”€ api_client.py
â”œâ”€â”€ tests/                 # Robustness, fairness, and negative tests
â”‚   â”œâ”€â”€ test_robustness.py
â”‚   â”œâ”€â”€ test_fairness.py
â”‚   â”œâ”€â”€ test_negative_inputs.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ .env.example           # Environment variable template
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

----

ğŸ§± Architecture Overview


flowchart TD
    A["Pytest Test Suite"] --> B["API Client (requests)"]
    B --> C["Local Mock AI Server (Flask classifier)"]
    C --> D["Prediction + Confidence Response"]

    subgraph R["Robustness Tests"]
        R1["Case Variation"]
        R2["Punctuation Noise"]
        R3["Spacing Variations"]
    end

    subgraph F["Fairness Tests"]
        F1["Gender Swap"]
        F2["Nationality Swap"]
        F3["Neutrality Check"]
    end

    A --> R
    A --> F

This diagram visualizes how your pytest tests interact with the API client and the local mock AI server.



ğŸš€ How to Run the Project

1ï¸âƒ£ Activate Virtual Environment

cd ai-robustness-fairness-tests
source .venv/bin/activate

2ï¸âƒ£ Start the Mock AI Server (Terminal 1)

python3 mock_api/server.py

3ï¸âƒ£ Run Tests (Terminal 2)

cd ai-robustness-fairness-tests
source .venv/bin/activate
pytest -v

4ï¸âƒ£ Run Specific Tests

pytest tests/test_robustness.py -v
pytest tests/test_fairness.py -v
pytest tests/test_negative_inputs.py -v


âœ”ï¸ Test Coverage Summary

| Input Variant     | Expected   |
| ----------------- | ---------- |
| CASE variation    | Same label |
| Extra spaces      | Same label |
| Punctuation noise | Same label |


Fairness Tests

| Variant Pair                       | Expected         |
| ---------------------------------- | ---------------- |
| â€œHe isâ€¦â€ vs â€œShe isâ€¦â€              | Equal prediction |
| â€œIndian peopleâ€ vs â€œGerman peopleâ€ | Equal prediction |
| â€œmanâ€ vs â€œwomanâ€                   | Equal prediction |


Negative Tests

-Missing payload â†’ 400

-Empty string â†’ 400

-Invalid types â†’ 400

----

ğŸ§  Why This Project Is Useful for AI QA Roles

Modern AI systems must be:

Bias-resistant

Robust against noise

Consistent across demographic variations

This project demonstrates:

âœ” Real-world ML testing scenarios
âœ” Methodical robustness checks
âœ” Practical fairness evaluation
âœ” Clean automated testing architecture
